{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ma_v03 import MA_PARTY\n",
    "import supersuit as ss\n",
    "from stable_baselines3 import PPO\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Helper classes\n",
    "import track_time\n",
    "import analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track CPU/RAM\n",
    "import threading\n",
    "import psutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def display_cpu():\n",
    "    global running\n",
    "    global cpu_total\n",
    "    global ram_total\n",
    "    global start_time\n",
    "\n",
    "    running = True\n",
    "    cpu_total = 0\n",
    "    ram_total = 0\n",
    "    start_time = time.strftime('%H%M%S')\n",
    "\n",
    "    # start loop\n",
    "    while running:\n",
    "        \"CPU-Auslastung oder -Nutzung bezeichnet die Zeit, die ein Computer benötigt, um bestimmte Informationen zu verarbeiten.\"\n",
    "        cpu_temp = psutil.cpu_percent(interval=1)\n",
    "        # print('Die CPU-Auslastung beträgt:', cpu_temp)\n",
    "        cpu_total += cpu_temp\n",
    "\n",
    "        \"RAM-Auslastung oder HAUPTSPEICHER-AUSLASTUNG bezeichnet dagegen die Zeit, die RAM von einem bestimmten System zu einem bestimmten Zeitpunkt genutzt wird.\"\n",
    "        ram_temp = psutil.virtual_memory()[2]\n",
    "        # print('RAM memory % used:', ram_temp)\n",
    "        ram_total += ram_temp\n",
    "\n",
    "def start():\n",
    "    global t\n",
    "\n",
    "    # create thread and start it\n",
    "    t = threading.Thread(target=display_cpu)\n",
    "    t.start()\n",
    "    \n",
    "def stop():\n",
    "    global running\n",
    "    global end_time\n",
    "    global t\n",
    "\n",
    "    end_time = time.strftime('%H%M%S')\n",
    "\n",
    "    # use `running` to stop loop in thread so thread will end\n",
    "    running = False\n",
    "\n",
    "    # wait for thread's end\n",
    "    t.join()\n",
    "\n",
    "    print(\"############################################\")\n",
    "    print(\"############################################\")\n",
    "    print(\"############################################\")\n",
    "    print(\"############################################\")\n",
    "    cpu_temp = round(cpu_total, 2)\n",
    "    ram_temp = round(ram_total, 2)\n",
    "    print(f\"cpu_total: {cpu_temp}\")\n",
    "    print(f\"ram_total: {ram_temp}\")\n",
    "\n",
    "    t1 = datetime.strptime(start_time, '%H%M%S')\n",
    "    t2 = datetime.strptime(end_time, '%H%M%S')\n",
    "    duration = t2 - t1\n",
    "    seconds = duration.total_seconds()\n",
    "\n",
    "    if seconds > 0:\n",
    "        cpu_usage = round(cpu_total / seconds, 2)\n",
    "        ram_usage = round(ram_total / seconds, 2)\n",
    "        ram = round(ram_usage / 100 * 32, 2)\n",
    "\n",
    "        print(f\"cpu: {cpu_usage}\\nram: {ram_usage} % {ram} GB\\ntime: {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train MARL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'threading' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     34\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mtrack_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m train(env_fn\u001b[38;5;241m=\u001b[39mMA_PARTY, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100_000\u001b[39m)\n\u001b[0;32m     37\u001b[0m track_time\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[1;32mc:\\Users\\cehmaxim19\\Documents\\CEH_Master_Thesis_Project\\track_time.py:28\u001b[0m, in \u001b[0;36mstart\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m t\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# create thread and start it\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mthreading\u001b[49m\u001b[38;5;241m.\u001b[39mThread(target\u001b[38;5;241m=\u001b[39mdisplay_cpu)\n\u001b[0;32m     29\u001b[0m t\u001b[38;5;241m.\u001b[39mstart()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'threading' is not defined"
     ]
    }
   ],
   "source": [
    "def train(env_fn, steps: int = 10_000, seed: int = 0, **env_kwargs):\n",
    "    env = env_fn(**env_kwargs)\n",
    "    \n",
    "    # env = parallel_to_aec(env)\n",
    "    # parallel_env = parallel_wrapper_fn(env)\n",
    "\n",
    "    print(f\"Preparing training on {str(env.metadata['name'])}.\")\n",
    "\n",
    "    # env = ss.black_death_v3(env)\n",
    "    \n",
    "    obs, _ = env.reset(seed)\n",
    "    \n",
    "    # env = ss.agent_indicator_v0(env)\n",
    "    env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "    \n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        verbose=3,\n",
    "        batch_size=256,\n",
    "        tensorboard_log=\"./ppo_ma_party_tensorboard/\",\n",
    "    )\n",
    "    \n",
    "    model.learn(total_timesteps=steps)\n",
    "    model_name = f\"./ma_models/{env.unwrapped.metadata.get('name')}_{steps}_{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    "    model.save(model_name)\n",
    "\n",
    "    print(\"Model has been saved.\")\n",
    "    print(f\"Finished training on {str(env.unwrapped.metadata['name'])}.\")\n",
    "    print(model_name)\n",
    "\n",
    "    env.close()\n",
    "    \n",
    "model_name = None\n",
    "track_time.start()\n",
    "train(env_fn=MA_PARTY, steps=100_000)\n",
    "track_time.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MARL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward per round: 88.03\n",
      "Success rate: 81.8 %\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"./ma_models/marl_heroes_vs_goblins_v01_20240731-121106\")\n",
    "env = MA_PARTY(render_mode=\"human\") # , debug_mode=True)\n",
    "episode_data = []\n",
    "step_data = []\n",
    "\n",
    "reward_total = 0\n",
    "all_heroes_alive = 0\n",
    "episodes = 100000\n",
    "\n",
    "for episode in range(1, episodes):\n",
    "    # print(f\"Run {run}\")\n",
    "    \n",
    "    observations, infos = env.reset()\n",
    "    while env.agents:\n",
    "        \n",
    "        actions = {agent: model.predict(observations[agent])[0].item() for agent in env.agents}       \n",
    "        # actions = {agent: env.action_space(agent).sample(infos[agent][\"action_mask\"]) for agent in env.agents} # action_mask\n",
    "        # actions = {agent: env.action_space(agent).sample() for agent in env.agents} # random\n",
    "\n",
    "        observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "        \n",
    "        step_data.append({\"rogue\": actions[\"rogue\"], \"fighter\": actions[\"fighter\"], \"wizard\": actions[\"wizard\"], \"cleric\": actions[\"cleric\"]})\n",
    "\n",
    "    episode_data.append({\"episode\": episode, \"reward\": rewards[\"rogue\"]})\n",
    "    env.close()\n",
    "\n",
    "# write reward per episode data\n",
    "with open('data/marl_100_000.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['episode', 'reward']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(episode_data)\n",
    "\n",
    "# write action per step data\n",
    "with open('data/marl_100_000_actions.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['rogue', 'fighter', 'wizard', 'cleric']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(step_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### RESULTS ###############\n",
      "Mean: 88.12\n",
      "Q1: 100.0\n",
      "Median: 100.0\n",
      "Q3: 100.0\n",
      "Min: -100\n",
      "Max: 100\n",
      "IQR (Interquartile Range): 0.0\n",
      "\n",
      "All heroes survive: 81.88 %\n",
      "3 heroes survive: 12.51 %\n",
      "2 heroes survive: 2.9 %\n",
      "1 heroes survive: 0.1 %\n",
      "Heroes die: 2.3 %\n",
      "Heros run away: 0.3 %\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the CSV file\n",
    "data = pd.read_csv('data/marl_100_000.csv')\n",
    "\n",
    "# Analyse the data\n",
    "analyse.analyze_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rogue:\n",
      "Counts:\n",
      "  Action 0: 46\n",
      "  Action 1: 386\n",
      "  Action 2: 5589\n",
      "  Action 3: 49\n",
      "  Action 4: 9\n",
      "  Action 5: 24\n",
      "  Action 6: 11\n",
      "  Action 7: 11\n",
      "  Action 8: 21\n",
      "Frequencies (%):\n",
      "  Action 0: 0.75%\n",
      "  Action 1: 6.28%\n",
      "  Action 2: 90.94%\n",
      "  Action 3: 0.80%\n",
      "  Action 4: 0.15%\n",
      "  Action 5: 0.39%\n",
      "  Action 6: 0.18%\n",
      "  Action 7: 0.18%\n",
      "  Action 8: 0.34%\n",
      "\n",
      "fighter:\n",
      "Counts:\n",
      "  Action 0: 45\n",
      "  Action 1: 398\n",
      "  Action 2: 5564\n",
      "  Action 3: 53\n",
      "  Action 4: 11\n",
      "  Action 5: 27\n",
      "  Action 6: 21\n",
      "  Action 7: 8\n",
      "  Action 8: 19\n",
      "Frequencies (%):\n",
      "  Action 0: 0.73%\n",
      "  Action 1: 6.48%\n",
      "  Action 2: 90.53%\n",
      "  Action 3: 0.86%\n",
      "  Action 4: 0.18%\n",
      "  Action 5: 0.44%\n",
      "  Action 6: 0.34%\n",
      "  Action 7: 0.13%\n",
      "  Action 8: 0.31%\n",
      "\n",
      "wizard:\n",
      "Counts:\n",
      "  Action 0: 46\n",
      "  Action 1: 414\n",
      "  Action 2: 5564\n",
      "  Action 3: 47\n",
      "  Action 4: 7\n",
      "  Action 5: 19\n",
      "  Action 6: 19\n",
      "  Action 7: 8\n",
      "  Action 8: 22\n",
      "Frequencies (%):\n",
      "  Action 0: 0.75%\n",
      "  Action 1: 6.74%\n",
      "  Action 2: 90.53%\n",
      "  Action 3: 0.76%\n",
      "  Action 4: 0.11%\n",
      "  Action 5: 0.31%\n",
      "  Action 6: 0.31%\n",
      "  Action 7: 0.13%\n",
      "  Action 8: 0.36%\n",
      "\n",
      "cleric:\n",
      "Counts:\n",
      "  Action 0: 55\n",
      "  Action 1: 379\n",
      "  Action 2: 5569\n",
      "  Action 3: 56\n",
      "  Action 4: 10\n",
      "  Action 5: 31\n",
      "  Action 6: 20\n",
      "  Action 7: 13\n",
      "  Action 8: 13\n",
      "Frequencies (%):\n",
      "  Action 0: 0.89%\n",
      "  Action 1: 6.17%\n",
      "  Action 2: 90.61%\n",
      "  Action 3: 0.91%\n",
      "  Action 4: 0.16%\n",
      "  Action 5: 0.50%\n",
      "  Action 6: 0.33%\n",
      "  Action 7: 0.21%\n",
      "  Action 8: 0.21%\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('data/marl_100_000_actions.csv')\n",
    "\n",
    "# Analyse the data\n",
    "analyse.analyze_action_spread(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
